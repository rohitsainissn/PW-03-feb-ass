{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f2b237",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "\n",
    "Ans:- Simple lenear regression have one independent variable and one dependent variable, we use the independent variable to predict the dependent variable, on the other hand we have multiple independent variable in multiple linear regression and one dependent variable.\n",
    "simple linear regression example:- Hight and weight dataset where we have to train our model using hight to predict weight.\n",
    "\n",
    "Multiple linear regression example:- Hight, color, state, gender are independent variable, weight is dependent variable.\n",
    "\n",
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "\n",
    "Ans:- assumptions are:-\n",
    "\n",
    "1) dependent and independent variable have linear relationship.\n",
    "2) homoscedasticity in data\n",
    "3) independent variable data is normally distributed.\n",
    "\n",
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "\n",
    "Ans:- in linear regression model we have to find the best fit line, and the line can be defined by the equation y=mx+c where m is slop of the line and c is y intercept. slop means the derivative of x wrt y. hence it tells how much x changes when we change y. the intercept tells if value of y when x is zero.\n",
    "\n",
    "For example, suppose we want to predict the salary of an employee based on their years of experience. We can use a linear regression model where the independent variable is the years of experience and the dependent variable is the salary. The model can be expressed as:\n",
    "\n",
    "Salary = intercept + slope * Years of experience\n",
    "\n",
    "The slope in this model represents the expected increase in the salary for every one-year increase in the years of experience. For instance, if the slope is 1000, it means that an increase of one year of experience is associated with an increase of $1000 in the salary.\n",
    "\n",
    "The intercept in this model represents the expected salary of an employee with zero years of experience. If the intercept is$30,000,it means that a person with no experience would be expected to earn a salary of $30,000.\n",
    "\n",
    "So, interpreting the slope and intercept in a linear regression model can help us understand the relationship between the independent and dependent variables, and make predictions based on that relationship in real-world scenarios.\n",
    "\n",
    "\n",
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "Ans:- To know the best slop and best intercept of line with least error. we use a concept known as gradient descent in which we first allot a rendom values of slop, then calculate its gradient, which tells that whether to increse the weight or decrease the weight to get the optimum value. in the next step we reduce or increase the weight as per calculation and the again find the result and calculate in which direction we have to go to get the desire answer.\n",
    "\n",
    "In machine learning we use gradient descent to find the correct weights used in equation to get the minimum cost function.\n",
    "\n",
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "Simple lenear regression have one independent variable and one dependent variable, we use the independent variable to predict the dependent variable, on the other hand we have multiple independent variable in multiple linear regression and one dependent variable.\n",
    "simple linear regression example:- Hight and weight dataset where we have to train our model using hight to predict weight.\n",
    "\n",
    "Multiple linear regression example:- Hight, color, state, gender are independent variable, weight is dependent variable.\n",
    "\n",
    "\n",
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "\n",
    "Multicollinearity is a common problem that arises in multiple linear regression when there is a high correlation between two or more independent variables in the model. It occurs when the independent variables are highly correlated with each other, making it difficult for the regression model to distinguish the unique contribution of each variable to the dependent variable. This can lead to unreliable and inaccurate estimates of the regression coefficients and the predictive power of the model.\n",
    "\n",
    "Calculate the correlation matrix among the independent variables and then Remove one or more highly correlated independent variables from the model.\n",
    "\n",
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "Unlike linear regression, which models the relationship between the independent variable and dependent variable as a straight line, polynomial regression models the relationship as an nth-degree polynomial function. The degree of the polynomial determines the complexity of the curve that is fitted to the data.\n",
    "\n",
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "Ans:- Advantages of Polynomial Regression:\n",
    "\n",
    "Flexibility: Polynomial regression can fit a curve to the data, making it more flexible than linear regression, which can only fit a straight line. This flexibility allows for more accurate modeling of nonlinear relationships between the independent variable and dependent variable.\n",
    "\n",
    "Better fit: By capturing the nonlinear relationships between the variables, polynomial regression can often result in a better fit to the data than linear regression.\n",
    "\n",
    "Disadvantages of Polynomial Regression:\n",
    "\n",
    "Overfitting: Polynomial regression models can easily overfit the data if the degree of the polynomial is too high. Overfitting can lead to poor generalization to new data and reduce the model's predictive accuracy.\n",
    "\n",
    "Interpretation: Polynomial regression models can be more difficult to interpret than linear regression models. With a linear regression model, the relationship between the variables is straightforward and easy to explain, but with polynomial regression, the relationship is more complex.\n",
    "\n",
    "When the data is not giving accurate by linear regression hence there might be not a straight line relashionship hence we can go for polynomial regression for better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e6279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
