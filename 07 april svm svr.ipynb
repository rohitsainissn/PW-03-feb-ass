{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657d592f",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\n",
    "\n",
    "Ans:-In machine learning, kernel functions are commonly used to transform input data into a higher-dimensional feature space, where linear models can be used to make better predictions. Polynomial functions can be used as a type of kernel function, specifically as a polynomial kernel function.\n",
    "\n",
    "A polynomial kernel function is defined as:\n",
    "\n",
    "K(x, y) = (x^T y + c)^d\n",
    "\n",
    "where x and y are input vectors, c is a constant, and d is the degree of the polynomial. This function computes the dot product of the input vectors in a higher-dimensional space.\n",
    "\n",
    "\n",
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b624040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Precision: 0.8446601941747572\n",
      "Recall: 0.90625\n",
      "F1 score: 0.8743718592964823\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Generate a sample dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=0, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the SVM classifier with a polynomial kernel\n",
    "poly_svm = svm.SVC(kernel='poly', degree=3, C=1.0, gamma='auto')\n",
    "\n",
    "# Train the SVM classifier on the training set\n",
    "poly_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the testing set\n",
    "y_pred = poly_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the SVM classifier using classification metrics\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5956b7b9",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "Ans:- In Support Vector Regression (SVR), epsilon is a hyperparameter that controls the width of the epsilon-insensitive tube around the regression line. The epsilon-insensitive tube is the region within which no penalty is given for errors made by the SVR model. The larger the value of epsilon, the wider the epsilon-insensitive tube.\n",
    "\n",
    "Increasing the value of epsilon can lead to an increase in the number of support vectors in SVR. This is because a wider epsilon-insensitive tube allows more data points to fall within the tube without incurring a penalty, and hence, more support vectors are required to define the regression line. Conversely, decreasing the value of epsilon leads to a narrower epsilon-insensitive tube, which may cause some data points to be penalized, resulting in fewer support vectors.\n",
    "\n",
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "ANS:- \n",
    "\n",
    "Kernal function is used for featurisation, it increases the dimension of the dataset so that it can be classified, they are of various type like polynomial kernel, rvf kernal etc.\n",
    "\n",
    "C parameter is used to regulate regularisation term, if C increase effect of regularization term decreases and vice versa.\n",
    "\n",
    "epsilon paramenter:   Epsilon in the epsilon-SVR model. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value. Must be non-negative.\n",
    "\n",
    "Gamma parameter is Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99184850",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Q5. Assignment:\n",
    "L Import the necessary libraries and load the dataseg\n",
    "L Split the dataset into training and testing setZ\n",
    "L Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "L Create an instance of the SVC classifier and train it on the training datW\n",
    "L hse the trained classifier to predict the labels of the testing datW\n",
    "L Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "L Train the tuned classifier on the entire dataseg\n",
    "L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a2aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5acd8424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3     4     5     6     7     8     9   ...   47  \\\n",
       "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.0   \n",
       "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.0   \n",
       "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0   \n",
       "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...  ...   \n",
       "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "\n",
       "         48     49   50     51     52     53     54   55    56  \n",
       "0     0.000  0.000  0.0  0.778  0.000  0.000  3.756   61   278  \n",
       "1     0.000  0.132  0.0  0.372  0.180  0.048  5.114  101  1028  \n",
       "2     0.010  0.143  0.0  0.276  0.184  0.010  9.821  485  2259  \n",
       "3     0.000  0.137  0.0  0.137  0.000  0.000  3.537   40   191  \n",
       "4     0.000  0.135  0.0  0.135  0.000  0.000  3.537   40   191  \n",
       "...     ...    ...  ...    ...    ...    ...    ...  ...   ...  \n",
       "4596  0.000  0.232  0.0  0.000  0.000  0.000  1.142    3    88  \n",
       "4597  0.000  0.000  0.0  0.353  0.000  0.000  1.555    4    14  \n",
       "4598  0.102  0.718  0.0  0.000  0.000  0.000  1.404    6   118  \n",
       "4599  0.000  0.057  0.0  0.000  0.000  0.000  1.147    5    78  \n",
       "4600  0.000  0.000  0.0  0.125  0.000  0.000  1.250    5    40  \n",
       "\n",
       "[4601 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Load the data from the file into a DataFrame\n",
    "df = pd.read_csv('spambase.data', header=None)\n",
    "X = df.drop(57, axis=1)\n",
    "y=df[57]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3efe58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.342434</td>\n",
       "      <td>0.330885</td>\n",
       "      <td>0.712859</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>-0.350266</td>\n",
       "      <td>-0.291794</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-0.323302</td>\n",
       "      <td>-0.371364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>-0.514307</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>0.624007</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.045247</td>\n",
       "      <td>0.045298</td>\n",
       "      <td>-0.008724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345359</td>\n",
       "      <td>0.051909</td>\n",
       "      <td>0.435130</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>-0.256117</td>\n",
       "      <td>0.672399</td>\n",
       "      <td>0.244743</td>\n",
       "      <td>-0.088010</td>\n",
       "      <td>-0.323302</td>\n",
       "      <td>1.086711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>-0.026007</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>0.126203</td>\n",
       "      <td>0.423783</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>-0.002443</td>\n",
       "      <td>0.250563</td>\n",
       "      <td>1.228324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.145921</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>0.851723</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>1.364846</td>\n",
       "      <td>0.343685</td>\n",
       "      <td>0.193644</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>1.974017</td>\n",
       "      <td>0.016422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.117376</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>0.008496</td>\n",
       "      <td>0.440053</td>\n",
       "      <td>-0.079754</td>\n",
       "      <td>0.145921</td>\n",
       "      <td>2.221106</td>\n",
       "      <td>3.258733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.342434</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>-0.556761</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>0.472573</td>\n",
       "      <td>-0.350266</td>\n",
       "      <td>0.500237</td>\n",
       "      <td>1.308402</td>\n",
       "      <td>0.789462</td>\n",
       "      <td>0.605857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>-0.007511</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>-0.161934</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.052150</td>\n",
       "      <td>-0.062466</td>\n",
       "      <td>-0.152222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.342434</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>-0.556761</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>0.472573</td>\n",
       "      <td>-0.350266</td>\n",
       "      <td>0.500237</td>\n",
       "      <td>1.308402</td>\n",
       "      <td>0.789462</td>\n",
       "      <td>0.605857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>-0.014910</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>-0.164387</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.052150</td>\n",
       "      <td>-0.062466</td>\n",
       "      <td>-0.152222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.672880</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>0.673183</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>-0.464314</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>-0.291794</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-0.323302</td>\n",
       "      <td>-0.371364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>0.343917</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>-0.329912</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.127640</td>\n",
       "      <td>-0.252336</td>\n",
       "      <td>-0.322110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>-0.342434</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>-0.556761</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>-0.464314</td>\n",
       "      <td>-0.350266</td>\n",
       "      <td>-0.291794</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-0.323302</td>\n",
       "      <td>-0.371364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>-0.514307</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>0.102907</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.114623</td>\n",
       "      <td>-0.247205</td>\n",
       "      <td>-0.444165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.640128</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>0.038373</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>-0.464314</td>\n",
       "      <td>-0.350266</td>\n",
       "      <td>-0.291794</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-0.323302</td>\n",
       "      <td>-0.371364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>0.260533</td>\n",
       "      <td>2.141746</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>-0.329912</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.119382</td>\n",
       "      <td>-0.236941</td>\n",
       "      <td>-0.272628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>2.801763</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>-0.556761</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>-0.350266</td>\n",
       "      <td>-0.291794</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-0.323302</td>\n",
       "      <td>-0.371364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>-0.303450</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>-0.329912</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.127483</td>\n",
       "      <td>-0.242073</td>\n",
       "      <td>-0.338604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>-0.342434</td>\n",
       "      <td>-0.165072</td>\n",
       "      <td>0.732697</td>\n",
       "      <td>-0.0469</td>\n",
       "      <td>-0.464314</td>\n",
       "      <td>-0.350266</td>\n",
       "      <td>-0.291794</td>\n",
       "      <td>-0.262562</td>\n",
       "      <td>-0.323302</td>\n",
       "      <td>-0.371364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>-0.158453</td>\n",
       "      <td>-0.514307</td>\n",
       "      <td>-0.155198</td>\n",
       "      <td>-0.176648</td>\n",
       "      <td>-0.308355</td>\n",
       "      <td>-0.103048</td>\n",
       "      <td>-0.124236</td>\n",
       "      <td>-0.242073</td>\n",
       "      <td>-0.401281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2       3         4         5         6   \\\n",
       "0    -0.342434  0.330885  0.712859 -0.0469  0.011565 -0.350266 -0.291794   \n",
       "1     0.345359  0.051909  0.435130 -0.0469 -0.256117  0.672399  0.244743   \n",
       "2    -0.145921 -0.165072  0.851723 -0.0469  1.364846  0.343685  0.193644   \n",
       "3    -0.342434 -0.165072 -0.556761 -0.0469  0.472573 -0.350266  0.500237   \n",
       "4    -0.342434 -0.165072 -0.556761 -0.0469  0.472573 -0.350266  0.500237   \n",
       "...        ...       ...       ...     ...       ...       ...       ...   \n",
       "4596  0.672880 -0.165072  0.673183 -0.0469 -0.464314  0.781971 -0.291794   \n",
       "4597 -0.342434 -0.165072 -0.556761 -0.0469 -0.464314 -0.350266 -0.291794   \n",
       "4598  0.640128 -0.165072  0.038373 -0.0469 -0.464314 -0.350266 -0.291794   \n",
       "4599  2.801763 -0.165072 -0.556761 -0.0469  0.011565 -0.350266 -0.291794   \n",
       "4600 -0.342434 -0.165072  0.732697 -0.0469 -0.464314 -0.350266 -0.291794   \n",
       "\n",
       "            7         8         9   ...        47        48        49  \\\n",
       "0    -0.262562 -0.323302 -0.371364  ... -0.111546 -0.158453 -0.514307   \n",
       "1    -0.088010 -0.323302  1.086711  ... -0.111546 -0.158453 -0.026007   \n",
       "2     0.036670  1.974017  0.016422  ... -0.111546 -0.117376  0.014684   \n",
       "3     1.308402  0.789462  0.605857  ... -0.111546 -0.158453 -0.007511   \n",
       "4     1.308402  0.789462  0.605857  ... -0.111546 -0.158453 -0.014910   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4596 -0.262562 -0.323302 -0.371364  ... -0.111546 -0.158453  0.343917   \n",
       "4597 -0.262562 -0.323302 -0.371364  ... -0.111546 -0.158453 -0.514307   \n",
       "4598 -0.262562 -0.323302 -0.371364  ... -0.111546  0.260533  2.141746   \n",
       "4599 -0.262562 -0.323302 -0.371364  ... -0.111546 -0.158453 -0.303450   \n",
       "4600 -0.262562 -0.323302 -0.371364  ... -0.111546 -0.158453 -0.514307   \n",
       "\n",
       "            50        51        52        53        54        55        56  \n",
       "0    -0.155198  0.624007 -0.308355 -0.103048 -0.045247  0.045298 -0.008724  \n",
       "1    -0.155198  0.126203  0.423783  0.008763 -0.002443  0.250563  1.228324  \n",
       "2    -0.155198  0.008496  0.440053 -0.079754  0.145921  2.221106  3.258733  \n",
       "3    -0.155198 -0.161934 -0.308355 -0.103048 -0.052150 -0.062466 -0.152222  \n",
       "4    -0.155198 -0.164387 -0.308355 -0.103048 -0.052150 -0.062466 -0.152222  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4596 -0.155198 -0.329912 -0.308355 -0.103048 -0.127640 -0.252336 -0.322110  \n",
       "4597 -0.155198  0.102907 -0.308355 -0.103048 -0.114623 -0.247205 -0.444165  \n",
       "4598 -0.155198 -0.329912 -0.308355 -0.103048 -0.119382 -0.236941 -0.272628  \n",
       "4599 -0.155198 -0.329912 -0.308355 -0.103048 -0.127483 -0.242073 -0.338604  \n",
       "4600 -0.155198 -0.176648 -0.308355 -0.103048 -0.124236 -0.242073 -0.401281  \n",
       "\n",
       "[4601 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled\n",
    "X= pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "885f260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       531\n",
      "           1       0.95      0.89      0.92       390\n",
      "\n",
      "    accuracy                           0.93       921\n",
      "   macro avg       0.94      0.93      0.93       921\n",
      "weighted avg       0.94      0.93      0.93       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred= model.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1380f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 3.745401188473625, 'degree': 8, 'gamma': 0.021544346900318832, 'kernel': 'rbf'}\n",
      "Best Accuracy Score:  0.9298913043478262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# define the parameter space to search over\n",
    "param_distributions = {\n",
    "    'C': uniform(loc=0, scale=10),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': randint(low=1, high=10),\n",
    "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, num=10)),\n",
    "}\n",
    "\n",
    "# create an SVC model\n",
    "svc = SVC()\n",
    "\n",
    "# create a RandomizedSearchCV object with 10-fold cross-validation\n",
    "rs = RandomizedSearchCV(estimator=svc, \n",
    "                        param_distributions=param_distributions, \n",
    "                        n_iter=5, \n",
    "                        cv=10, \n",
    "                        random_state=42)\n",
    "\n",
    "# fit the model to the data\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "# print the best parameters and accuracy score\n",
    "print(\"Best Parameters: \", rs.best_params_)\n",
    "print(\"Best Accuracy Score: \", rs.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a1ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C= 3.745401188473625, degree = 8, gamma = 0.021544346900318832, kernel = 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6617b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       531\n",
      "           1       0.95      0.90      0.93       390\n",
      "\n",
      "    accuracy                           0.94       921\n",
      "   macro avg       0.94      0.94      0.94       921\n",
      "weighted avg       0.94      0.94      0.94       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred= model.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc77765e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=3.745401188473625, degree=8, gamma=0.021544346900318832)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=3.745401188473625, degree=8, gamma=0.021544346900318832)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=3.745401188473625, degree=8, gamma=0.021544346900318832)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(C= 3.745401188473625, degree = 8, gamma = 0.021544346900318832, kernel = 'rbf')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "329ab536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svr_model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model for further use\n",
    "from joblib import dump, load\n",
    "dump(model, 'svr_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602813d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
