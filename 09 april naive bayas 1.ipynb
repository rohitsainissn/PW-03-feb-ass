{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72249b94",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Ans:- Bayes' theorem is a mathematical formula used in probability theory and statistics to calculate the conditional probability of an event based on prior knowledge of related events. \n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the probability of event A given that event B has occurred\n",
    "P(B|A) is the probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A\n",
    "P(B) is the prior probability of event B\n",
    "\n",
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "AnsL- \n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) is the probability of event A given that event B has occurred\n",
    "P(B|A) is the probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A\n",
    "P(B) is the prior probability of event B\n",
    "\n",
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Ans:- Suppose we have two machines, A gives 20% output and B give rest, A produce 1% defective items and B produces 3% defective item, if we get an defective item, then to find whether it is produced from A or B can be find out by bayas theorem\n",
    "\n",
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Ans:- Bayes' theorem uses conditional probabilities to calculate the posterior probability of an event, which is the probability of the event occurring after taking into account the new evidence or information. This posterior probability can then be used to make more informed decisions or predictions.\n",
    "\n",
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Ans:- Bernoulli Naive Bayes classifier: This classifier is often used when dealing with text classification tasks where the input features are binary (i.e., presence or absence of a word). It assumes that each feature is conditionally independent and that the probability distribution of each feature is a Bernoulli distribution.\n",
    "\n",
    "Multinomial Naive Bayes classifier: This classifier is also used for text classification tasks where the input features are the frequency of the words in the document. It assumes that the data is generated by a multinomial distribution and that the features are conditionally independent given the class.\n",
    "\n",
    "Gaussian Naive Bayes classifier: This classifier is used when dealing with continuous data where the distribution of the features is assumed to be Gaussian (normal). It assumes that the features are conditionally independent given the class.\n",
    "\n",
    "P(A|D) = P(D|A) * P(A) / P(D)\n",
    "\n",
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    " A3344333\n",
    " B2212223\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n",
    "\n",
    "\n",
    "To classify the new instance using Naive Bayes, we need to calculate the conditional probability of each class given the feature values, and then choose the class with the highest probability.\n",
    "\n",
    "Here's how we can calculate the conditional probabilities for each class:\n",
    "\n",
    "P(Class = A | X1 = 3, X2 = 4) = P(X1 = 3 | Class = A) * P(X2 = 4 | Class = A) * P(Class = A) = (1/3) * (3/4) * (1/2) = 1/8\n",
    "P(Class = B | X1 = 3, X2 = 4) = P(X1 = 3 | Class = B) * P(X2 = 4 | Class = B) * P(Class = B) = (2/3) * (2/3) * (1/2) = 4/18\n",
    "Since P(Class = B | X1 = 3, X2 = 4) > P(Class = A | X1 = 3, X2 = 4), Naive Bayes would predict that the new instance belongs to Class B.\n",
    "\n",
    "Therefore, the Naive Bayes classifier would predict that the new instance with features X1 = 3 and X2 = 4 belongs to Class B."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
