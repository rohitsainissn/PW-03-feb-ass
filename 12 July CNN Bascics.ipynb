{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815fdead",
   "metadata": {},
   "source": [
    "TOPIC: Understanding Pooling and Padding in CNN\n",
    "\n",
    "\n",
    "\n",
    "Submission Guidelines:\n",
    "Desccire the purpose and benefits of pooling in CNN.\n",
    "\n",
    "The main purpose of pooling is to reduce the size of feature maps, which in turn makes computation faster because the number of training parameters is reduced. We use maxpooling to reduce the size of feature map.\n",
    "\n",
    "\n",
    "Q Explain the diffecence retween min pooling and max pooling.\n",
    "\n",
    "Max pooling is used to reduce the size of featuremaps by extracting the maximum value from the pooling window, min pooling is used to perform opposite function, it reduces the size but takes the minimum values from the pooling window.\n",
    "\n",
    "\n",
    "Q Discuss the concept of padding in CNN and its significance.\n",
    "\n",
    "Padding is a technique used in Convolutional Neural Networks (CNNs) to add extra pixels or elements around the borders of an input feature map before applying convolutional operations. The purpose of padding is to preserve the spatial dimensions of the input and to avoid the reduction of feature map size during convolution. When a convolutional operation is performed without padding, the spatial dimensions of the feature map decrease with each convolution. \n",
    "\n",
    "\n",
    "Q Compace and contrast zero-padding and valid-padding in terms of theic effects on the output featuce map size.\n",
    "\n",
    "Zero-Padding:\n",
    "Zero-padding involves adding extra elements (usually with zero values) around the borders of the input feature map before applying convolution. The amount of padding added determines the size of the output feature map. Zero-padding is typically used with the \"same\" padding mode, where the output feature map has the same spatial dimensions as the input.\n",
    "Effects on Output Feature Map Size:\n",
    "\n",
    "When using zero-padding with the \"same\" mode, the output feature map will have the same spatial dimensions as the input feature map.\n",
    "If the convolutional filter has a size of F x F and padding P is applied, the output feature map's spatial dimensions will be: (W + 2P - F + 1) x (H + 2P - F + 1), where W and H are the width and height of the input feature map, respectively.\n",
    "\n",
    "Valid-Padding (No Padding):\n",
    "Valid-padding, also known as \"no padding,\" involves performing convolution without adding any extra elements to the input feature map. As a result, the convolutional filter cannot extend beyond the borders, and the output feature map's size will be smaller than the input feature map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c5445",
   "metadata": {},
   "source": [
    "TOPIC: Exploring LeNet\n",
    "\n",
    "\n",
    "Q Provide a brief overview of LeNet-5 architecture.\n",
    "\n",
    "The LeNet-5 architecture consists of seven layers, including two convolutional layers, two average pooling layers, and three fully connected layers. The input to the network is a grayscale image of size 32x32 pixels. The first two layers perform convolution with small filters, followed by average pooling to reduce spatial dimensions and retain important features. The next three layers are fully connected, acting as a traditional neural network, and leading to a final output layer.\n",
    "\n",
    "\n",
    "Q Desccire the key components of LeNet-5 and theic respective purposes.\n",
    "\n",
    "\n",
    "LeNet-5 consists of the following key components and their respective purposes:\n",
    "\n",
    "Input Layer: The input layer takes in a grayscale image of size 32x32 pixels. It serves as the starting point for the network's processing.\n",
    "\n",
    "Convolutional Layers: LeNet-5 has two convolutional layers. The purpose of these layers is to extract important features from the input image using small filters (5x5 and 5x5 in size, respectively). These filters slide over the input feature map, detecting patterns such as edges and textures.\n",
    "\n",
    "Activation Function: After each convolutional layer, a non-linear activation function (typically tanh or sigmoid) is applied element-wise to introduce non-linearity and increase the model's expressive power.\n",
    "\n",
    "Average Pooling Layers: Two average pooling layers follow the convolutional layers. They perform down-sampling, reducing the spatial dimensions of the feature maps and controlling the model's complexity. Average pooling computes the average value of a small window, preserving the most salient information.\n",
    "\n",
    "Fully Connected Layers: Three fully connected layers act as a traditional neural network. They receive the pooled feature maps as inputs and process them to generate high-level representations.\n",
    "\n",
    "Output Layer: The final layer consists of 10 neurons (for the MNIST dataset) with a softmax activation function to produce probabilities of the input image belonging to each digit class (0-9).\n",
    "\n",
    "Overall, LeNet-5 effectively combines convolution, pooling, and fully connected layers to perform digit recognition, providing a solid foundation for modern CNN architectures.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks.\n",
    "\n",
    "Advantages of LeNet-5:\n",
    "\n",
    "Efficiency: LeNet-5 was designed when computational resources were limited. Its relatively small size and simple architecture make it computationally efficient, making it suitable for low-resource environments.\n",
    "\n",
    "Feature Extraction: The convolutional layers in LeNet-5 effectively extract hierarchical features from images, enabling it to learn meaningful representations for image classification tasks.\n",
    "\n",
    "Translation Invariance: The average pooling layers help LeNet-5 achieve a degree of translation invariance, making it robust to small shifts in the input image.\n",
    "\n",
    "Limitations of LeNet-5:\n",
    "\n",
    "Limited Depth: LeNet-5 has a shallow architecture by modern standards. As a result, it may struggle to handle complex and large-scale image classification tasks that require deeper networks for capturing intricate patterns.\n",
    "\n",
    "Global Receptive Field: LeNet-5 has a limited receptive field due to small convolutional filters. It may not effectively capture long-range dependencies in high-resolution images.\n",
    "\n",
    "MNIST Specificity: LeNet-5 was primarily designed for the MNIST dataset, which contains small, grayscale images of digits. Its effectiveness may be limited when applied to more diverse and complex datasets.\n",
    "\n",
    "Performance: While LeNet-5 was groundbreaking at its time, its accuracy and performance may be outperformed by more modern CNN architectures with deeper layers and sophisticated components.\n",
    "\n",
    "\n",
    "qp Implement LeNet-5 using a deep learning framework of your choice (e.g., TensocFlow, PyTocch) and train it on a (e.g., MNIST). Evaluate its pecformance and provide insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad7df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 23:57:13.342672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 37s 38ms/step - loss: 0.2521 - accuracy: 0.9229 - val_loss: 0.0925 - val_accuracy: 0.9720\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 37s 39ms/step - loss: 0.0681 - accuracy: 0.9789 - val_loss: 0.0600 - val_accuracy: 0.9829\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 40s 43ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.0351 - val_accuracy: 0.9875\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 38s 41ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.0316 - val_accuracy: 0.9895\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 57s 61ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0390 - val_accuracy: 0.9874\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 34s 37ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 20s 21ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0298 - val_accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 0.0375 - val_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0178 - accuracy: 0.9943 - val_loss: 0.0284 - val_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0384 - val_accuracy: 0.9891\n",
      "Test accuracy: 0.9890999794006348\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "\n",
    "# Load and preprocess MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.reshape(-1, 28, 28, 1) / 255.0, x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# Define LeNet-5 architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69710bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d556b2a",
   "metadata": {},
   "source": [
    "TOPIC: Analyzing AlexNet\n",
    "\n",
    "Q Pcesent an ovecview of the AlexNet architecture.\n",
    "\n",
    "Input Layer: AlexNet takes an input image of size 227x227x3 (RGB), which is larger than the typical input size used in previous models at that time.\n",
    "\n",
    "Convolutional Layers: AlexNet has five convolutional layers, and the first convolutional layer uses a large 11x11 filter with a stride of 4 to capture high-level features in a broader context. The subsequent convolutional layers use smaller filters (3x3 or 5x5) with a stride of 1.\n",
    "\n",
    "Activation Function: After each convolutional layer, a non-linear activation function (ReLU) is applied to introduce non-linearity and allow the model to learn more complex features.\n",
    "\n",
    "Max Pooling Layers: AlexNet uses three max-pooling layers to reduce the spatial dimensions and control overfitting.\n",
    "\n",
    "Local Response Normalization: In the first two convolutional layers, local response normalization is applied to enhance generalization and improve the model's robustness.\n",
    "\n",
    "Fully Connected Layers: After the convolutional and pooling layers, there are three fully connected layers with a large number of neurons (e.g., 4096) to learn high-level representations.\n",
    "\n",
    "Dropout: To prevent overfitting, AlexNet employs dropout, a regularization technique, in the fully connected layers.\n",
    "\n",
    "Output Layer: The final layer is a softmax output layer with 1000 neurons, representing the 1000 classes in the ImageNet dataset.\n",
    "    \n",
    "ip Explain the architectucal innovations involvced in AlexNet that contributed to its breakthrough performance.\n",
    "\n",
    "Deep Convolutional Layers: AlexNet was one of the first CNN architectures to utilize multiple layers of convolutions, allowing it to capture hierarchical features from the input images. The depth of the network enabled it to learn complex and high-level representations, improving its classification performance.\n",
    "\n",
    "Large Convolutional Filters: The use of large 11x11 and 5x5 convolutional filters in the initial layers allowed AlexNet to capture high-level, context-rich features. These large filters efficiently extracted information from the images, especially in the first layer, which benefited from a larger receptive field.\n",
    "\n",
    "Local Response Normalization: AlexNet employed local response normalization in the first two convolutional layers. This normalization technique enhanced generalization by normalizing the responses of neighboring neurons, making the model more robust to variations in inputs.\n",
    "\n",
    "GPU Acceleration: The authors of AlexNet utilized GPUs for training, which significantly sped up the process and allowed the training of a large, deep network within a reasonable time frame.\n",
    "\n",
    "\n",
    "Q Discuss the role of convolutional layecs, pooling layers, and fully connected layecs in AlexNet.\n",
    "\n",
    "In AlexNet, convolutional layers play a vital role in feature extraction from input images. The deep convolutional layers with large and small filters capture hierarchical features, enabling the model to learn low-level edges and textures as well as high-level complex patterns.\n",
    "\n",
    "Pooling layers serve to downsample the feature maps, reducing the spatial dimensions and controlling overfitting. The max-pooling layers retain the most salient information, allowing the model to focus on essential features while reducing computational complexity.\n",
    "\n",
    "Fully connected layers act as a traditional neural network, processing the learned features from the convolutional and pooling layers to generate high-level representations. The large number of neurons in the fully connected layers enables the model to learn intricate relationships between features, facilitating classification and recognition tasks.\n",
    "\n",
    "\n",
    "Q Implement implement AlexNet using a deep learning framework of your choice (e.g., TensorFlow or PyTorch) and evaluate its performance on a dataset of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e93beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/352 [==============================] - 885s 3s/step - loss: 1.7894 - accuracy: 0.3113 - val_loss: 1.4078 - val_accuracy: 0.4914\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 866s 2s/step - loss: 1.3168 - accuracy: 0.5229 - val_loss: 1.1356 - val_accuracy: 0.5946\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 1429s 4s/step - loss: 1.0767 - accuracy: 0.6196 - val_loss: 1.0701 - val_accuracy: 0.6272\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 1051s 3s/step - loss: 0.9202 - accuracy: 0.6822 - val_loss: 0.8884 - val_accuracy: 0.6900\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 983s 3s/step - loss: 0.8002 - accuracy: 0.7256 - val_loss: 0.8578 - val_accuracy: 0.7118\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 20649s 59s/step - loss: 0.7048 - accuracy: 0.7607 - val_loss: 0.8106 - val_accuracy: 0.7314\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 829s 2s/step - loss: 0.6092 - accuracy: 0.7916 - val_loss: 0.7713 - val_accuracy: 0.7408\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 1177s 3s/step - loss: 0.5402 - accuracy: 0.8140 - val_loss: 0.7564 - val_accuracy: 0.7560\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 858s 2s/step - loss: 0.4687 - accuracy: 0.8411 - val_loss: 0.8098 - val_accuracy: 0.7482\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 824s 2s/step - loss: 0.4114 - accuracy: 0.8574 - val_loss: 0.8618 - val_accuracy: 0.7482\n",
      "Test accuracy: 0.7275999784469604\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define AlexNet architecture for CIFAR-10\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
    "    layers.Conv2D(512, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training loop\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f5e025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
