{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47869694",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Anomaly detection refers to the task of identifying unusual or abnormal observations or patterns in data that deviate significantly from the expected or normal behavior. Its purpose is to detect and flag instances that are different from the majority of the data, which could potentially indicate interesting or suspicious events, errors, or anomalies.\n",
    "\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "Lack of labeled anomaly data for training in unsupervised scenarios.\n",
    "Defining what constitutes normal behavior or establishing a baseline for comparison.\n",
    "Dealing with imbalanced data where anomalies are rare compared to normal instances.\n",
    "Handling high-dimensional and large-scale datasets efficiently.\n",
    "Differentiating anomalies from expected variations or noise.\n",
    "Identifying contextual anomalies that are only anomalous in specific contexts or conditions.\n",
    "\n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "Unsupervised anomaly detection aims to identify anomalies without prior knowledge or labeled data. It focuses on discovering patterns or outliers that are significantly different from the majority of the data. Supervised anomaly detection, on the other hand, requires labeled training data with known anomalies to learn a model that can classify new instances as normal or anomalous.\n",
    "\n",
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "Statistical methods: These algorithms utilize statistical techniques to model the normal behavior of the data and identify instances that significantly deviate from the expected patterns.\n",
    "\n",
    "Machine learning-based methods: These algorithms employ various machine learning techniques, such as clustering, classification, or density estimation, to differentiate normal and anomalous instances.\n",
    "\n",
    "Distance-based methods: These algorithms calculate distances or similarities between data points and use thresholds or density estimates to identify anomalies.\n",
    "\n",
    "Ensemble methods: These algorithms combine multiple models or base learners to improve the detection accuracy by leveraging diverse perspectives or voting schemes.\n",
    "\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "Normal instances are grouped together and form dense regions in the feature space.\n",
    "Anomalies are far away from normal instances and reside in sparse regions or have a dissimilar distribution.\n",
    "The distance or similarity measure used is appropriate for capturing the dissimilarity between instances.\n",
    "\n",
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "The LOF (Local Outlier Factor) algorithm computes anomaly scores based on the concept of local density. It measures the local deviation of an instance compared to its neighbors. The algorithm calculates the average density of the k nearest neighbors of each data point and compares it to the density of the data point itself. Higher values of the LOF indicate that the instance is less dense compared to its neighbors, suggesting it is more likely to be an anomaly.\n",
    "\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "Number of trees: It determines the number of isolation trees to be constructed in the ensemble. A larger number can potentially improve accuracy but increases computation time.\n",
    "\n",
    "Subsample size: It represents the number of samples drawn randomly from the dataset to construct each tree. A smaller subsample size can increase diversity and speed up training but may reduce accuracy.\n",
    "\n",
    "Contamination: It specifies the expected proportion of anomalies in the dataset and helps in setting the threshold for determining anomalies.\n",
    "\n",
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "\n",
    " If a data point has only 2 neighbors of the same class within a radius of 0.5 and KNN is used with K=10, the anomaly score for that data point would be relatively high. Having only a few neighbors of the same class within a small radius suggests that the data point is significantly different from its neighboring points, potentially indicating an anomaly.\n",
    "\n",
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
    "\n",
    "Ans:- In the Isolation Forest algorithm, the anomaly score for a data point is computed based on its average path length compared to the average path length of the trees. A smaller average path length implies that the data point is isolated more quickly and is likely to be an anomaly. Therefore, a data point with an average path length of 5.0 compared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
