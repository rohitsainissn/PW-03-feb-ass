{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b99d6b",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "Ans:- In Lasso we use L1 Reguralisation hence it reduces overfitting as well as make the unimportant feature's coefficient to zero i.e. it do feature sellection.\n",
    "\n",
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "Ans:- Lasso do feature selection by removing those features whose relivence is very less.\n",
    "\n",
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "Ans:- \n",
    "lasso = Lasso(alpha=0.1)  # set the regularization parameter\n",
    "lasso.fit(X, y)  # fit the model\n",
    "coefficients = lasso.coef_ \n",
    "for i, coef in enumerate(coefficients):\n",
    "    print(f\"{X.columns[i]}: {coef}\")\n",
    "\n",
    "positive cofficient shows the positive relation with independent variable and vice versa, larger coefficient shows the relation with independent is very high and vice versa\n",
    "\n",
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "Ans:- lambda is tuning paramenter if we increase the lambda then regularisation effect gets increase and more coefficients get shrink and remove, model with high lambda will get underfit, if lambda is less then the error portion of cost function will get effect and model try to reduce the error cause overfitting, so we use to choose the value for the best fit model.\n",
    "\n",
    "\n",
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "Ans:- No Lasso Regression cannot work on non-linear problem, but we can feature transpose the features like x^2, sin(x) or log(x) and then we can apply lasso.\n",
    "\n",
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "Ans:- Ridge uses L2 regularization hence it shrinks the coefficient, reduce overfitting and tackel multicolanirity, while lasso shinks the coefficient as well as make unimportant coefficient to zero hence do feature sellection by using L1 regularization.\n",
    "\n",
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "Ans:- Yes, In cases where there is high multicollinearity between input features, Lasso regression tends to select one of the correlated features while assigning zero coefficients to the others. By doing so, the model is able to maintain the most important features while reducing the effects of multicollinearity.\n",
    "\n",
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "Ans:- if lambda is small then error term is effective and we get the overfitting model, if lambda is high then regularizatio term is high and we get the removal of features and underfitting , hence we need to choose the optimum lambda for best result by hypertuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
