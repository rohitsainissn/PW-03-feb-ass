{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5489586",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "Ans:- min-max is a normalisation technique where we get all the values in range of 0 to 1, we use the formula = X_scaled = (X - X_min) / (X_max - X_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09eb7bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ],\n",
       "       [0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ],\n",
       "       [0.  ],\n",
       "       [0.25],\n",
       "       [0.5 ],\n",
       "       [0.75],\n",
       "       [1.  ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "lis = np.array([1,2,3,4,5,1,2,3,4,5,1,2,3,4,5])\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(lis.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9df765",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "Ans: In contrast to Min-Max scaling, which scales the values of a feature to a fixed range between 0 and 1, Unit Vector scaling preserves the direction of the data points and only adjusts their magnitudes. Specifically, each data point is divided by the Euclidean norm of the feature vector:\n",
    "\n",
    "X_norm = X / ||X||\n",
    "\n",
    "where X is the original feature vector and ||X|| is its Euclidean norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "848606dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8758f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      " [1 2 3 4 5 1 2 3 4 5 1 2 3 4 5]\n",
      "Normalized data:\n",
      " [[0.07784989 0.15569979 0.23354968 0.31139958 0.38924947 0.07784989\n",
      "  0.15569979 0.23354968 0.31139958 0.38924947 0.07784989 0.15569979\n",
      "  0.23354968 0.31139958 0.38924947]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "\n",
    "# fit and transform the data\n",
    "data_norm = scaler.fit_transform(lis.reshape(1, -1) )\n",
    "\n",
    "print(\"Original data:\\n\", lis)\n",
    "print(\"Normalized data:\\n\", data_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2406187",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "PCA is a statistical technique used to reduce the dimension by keeping maximum possible information it can retain.\n",
    "\n",
    "PCA works by finding the directions of maximum variance in the data and projecting the data onto these directions, creating new variables that capture most of the variation in the original data. These new variables, called principal components, are linear combinations of the original variables and are uncorrelated with each other.\n",
    "\n",
    "Consider the example of house price with 100 of columns, out of 100 we choose the first few principal components that capture the majority of the variability in the data and use them as new variables to represent the data in a lower-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56149e3",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "Feature extraction is the process of transforming raw data into a smaller set of more meaningful features that can capture the most important information in the data. This is often done to simplify the data and reduce its dimensionality, which can improve the performance of machine learning algorithms and make the data easier to analyze and visualize.\n",
    "\n",
    "PCA can be used as a feature extraction technique by finding the principal components of the data, which can be used as new features to represent the data in a lower-dimensional space.\n",
    "\n",
    "example: Consider the example of house price with 100 of columns, out of 100 we choose the first few principal components that capture the majority of the variability in the data and use them as new variables to represent the data in a lower-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2e866",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "Ans:- as all the variable price, rating and delivery time is numeric value, hence we can use min-max scaling easily\n",
    "we can apply this formula to scale the data\n",
    "\n",
    "scaled_value = (original_value - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c470bfc",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "Ans:- PCA can be used as a feature extraction technique by finding the principal components of the data, which can be used as new features to represent the data in a lower-dimensional space. So we will plot the data and find few feature with max variances, then plot the points on the line capturing all the points, then this new line gives a new feature , similarly se sellect few more features and use them as new data set hence left with fewer features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf186cb4",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3763920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.21052632],\n",
       "       [0.47368421],\n",
       "       [0.73684211],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis = np.array([1, 5, 10, 15, 20])\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(lis.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758b3c9",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "Ans:-  We would choose the number of principal components to keep based on the amount of variance we want to retain in the data. we will do PCA and then according to result and our requirement we choose to retain the new features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
